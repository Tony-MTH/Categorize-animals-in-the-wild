{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iWildCam 2019 - FGVC6\n",
    "### Categorize animals in the wild\n",
    "\n",
    "> **Work done by**: Nwachukwu Anthony  \n",
    "> **Email**: nwachukwuanthony2015@gmail.com  \n",
    "> **Inspired by**: *Fastai online courses on Deep Learning*  \n",
    "> **Data from kaggle** competition, link below\n",
    "\n",
    "Camera Traps (or Wild Cams) enable the automatic collection of large quantities of image data. Biologists all over the world use camera traps to monitor biodiversity and population density of animal species. We have recently been making strides towards automating the species classification challenge in camera traps, but as we try to expand the scope of these models from specific regions where we have collected training data to nearby areas we are faced with an interesting probem: how do you classify a species in a new region that you may not have seen in previous training data?\n",
    "In order to tackle this problem, we have prepared a challenge where the training data and test data are from different regions, namely The American Southwest and the American Northwest. The species seen in each region overlap, but are not identical, and the challenge is to classify the test species correctly. To this end, we will allow training on our American Southwest data (from CaltechCameraTraps), on iNaturalist 2017/2018 data, and on simulated data generated from Microsoft AirSim. We have provided a taxonomy file mapping our classes into the iNat taxonomy.\n",
    "This is an FGVCx competition as part of the FGVC6 workshop at CVPR 2019, and is sponsored by Microsoft AI for Earth. There is a github page for the competition here.\n",
    "\n",
    "You will find the dataset on this website: https://www.kaggle.com/c/iwildcam-2019-fgvc6/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from fastai.vision import *\n",
    "import os\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the paths and Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the train csv.\n",
    "df = pd.read_csv('../input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since kaggle doesn't allow write on the iput directory, we create a new directory outside it where\n",
    "# we can freely work and make it the path\n",
    "path = Path(\"../working\")\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a new csv file for the train dataset. We save it working folder and name it \"trainmodified.csv\".\n",
    "# It contains the id and target labels of the train dataset\n",
    "df=df[['id', 'category_id']]\n",
    "sizeOfData = 3000 #Since the dataset is much for the RAM, we limit the size for each category to \"sizeOfData\"\n",
    "clases = list(set(df['category_id'].tolist()))\n",
    "df_row=df.loc[df['category_id'] == clases[0]][0:sizeOfData]\n",
    "for i in clases[1:]:\n",
    "    df1=df.loc[df['category_id'] == i][0:sizeOfData]\n",
    "    df_row = pd.concat([df_row, df1])\n",
    "df_row.to_csv(r'../working/trainmodified.csv', index = None, header=True)\n",
    "print(os.listdir(\"../working/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters and create the data for the model\n",
    "np.random.seed(42) #makes sure you get same results each time you run the code\n",
    "src = (ImageList.from_csv('../', 'working/trainmodified.csv', folder='input/train_images', suffix='.jpg')\n",
    "       .split_by_rand_pct(0.2)\n",
    "       .label_from_df(label_delim=' '))\n",
    "tfms = get_transforms()\n",
    "data = (src.transform(tfms, size=128)\n",
    "        .databunch().normalize(imagenet_stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data Classes:', data.classes)\n",
    "print('Length of Train set: '+str(len(data.train_ds))+', Length of Validation set: '+str(len(data.valid_ds)))\n",
    "data.show_batch(rows=3, figsize=(7,8)) #View portion of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the metrics. Use F-score\n",
    "acc_02 = partial(accuracy_thresh, thresh=0.2)\n",
    "f_score = partial(fbeta, thresh=0.2)\n",
    "#Use CNN (Convolutional Neural Network) and pretrained model (resnet50)  to train\n",
    "learn = cnn_learner(data, models.resnet50, metrics=[acc_02,f_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find and plot learning rate\n",
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set learning rate\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "learn.fit_one_cycle(5,slice(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it\n",
    "learn.save('stage-1-rn50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####learn.load('stage-1-rn50');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the model, that is, traing afresh without the pretrained model\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and plot the learning rate\n",
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "learn.fit_one_cycle(10, slice(1e-5, lr/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this latest trained model\n",
    "learn.save('stage-2-rn50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export()\n",
    "print(os.listdir(\"../working\"))\n",
    "print(os.listdir(\"../input\"))\n",
    "print(os.listdir(\"../\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ImageList.from_folder('../input/test_images')\n",
    "len(test)\n",
    "learn = load_learner('../', test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the prediction\n",
    "preds,_ = learn.get_preds(ds_type=DatasetType.Test)\n",
    "labelled_preds = [learn.data.classes[(pred).tolist().index(max((pred).tolist()))] for pred in preds]\n",
    "#Althernatively, you can replace line two with these two lines of code below\n",
    "#labels = np.argmax(preds, 1)\n",
    "#labelled_preds = [data.classes[int(x)] for x in labels]\n",
    "print(labelled_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predicted results to the working path as (submission.csv)\n",
    "fnames = [f.name[:-4] for f in learn.data.test_ds.items]\n",
    "tes = OrderedDict([('Id',fnames), ('Predicted', labelled_preds)] )\n",
    "df = pd.DataFrame.from_dict(tes)\n",
    "df.to_csv(path/'submission.csv', index=False)\n",
    "print(os.listdir(\"../working\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsubmit = pd.read_csv('../working/submission.csv')\n",
    "dfsubmit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
